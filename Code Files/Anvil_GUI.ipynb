{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anvil_GUI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUaH-ZJk_pq"
      },
      "source": [
        "## **Packages to be installed during Runtime**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTZBfBEBMoz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "943315bc-5901-4066-f125-335a82cdf530"
      },
      "source": [
        "pip install anvil-uplink #Helps you connect with the Anvil Server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/65/776713490bfd5145ddb87834355bf7936bd233b273098e37dc12f1ac253c/anvil_uplink-0.3.36-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hCollecting ws4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-cp37-none-any.whl size=45216 sha256=d75392150b940b690c0b4f71a5eb3400bf98959886a42359780ba9e932b6be47\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.36 argparse-1.4.0 ws4py-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUYHodmyG2Xd",
        "outputId": "0b3c3fcf-811f-4213-a580-4324df82ac62"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 65kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 38.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=a90deea964777cd5ef5e8f5b831e8d32f600e31905a8ee99c45f1b75b6860031\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Z1xzB7pJ_x"
      },
      "source": [
        "## **Import Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Yn7vM1AAUA"
      },
      "source": [
        "#To import the Anvil Server\n",
        "import anvil.server\n",
        "\n",
        "#For the Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "#For Data manipulation\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import linalg as ml_linalg\n",
        "from pyspark.mllib.linalg import Vectors as MLLibVectors\n",
        "\n",
        "#For NLP\n",
        "from pyspark.ml.feature import HashingTF,RegexTokenizer,StopWordsRemover\n",
        "from pyspark.mllib.classification import SVMModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nJMuDfgsQi7"
      },
      "source": [
        "## **Creating a Session and Loading the files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3zC6fz1AZuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa414e2-696b-4bd7-e244-5418b4aa5ebe"
      },
      "source": [
        "sc = SparkContext(); #Connection to Spark Cluster\n",
        "spark = SparkSession.builder.appName('Sentiment Analysis').getOrCreate() #Create a Spark Session\n",
        "anvil.server.connect(\"UWYF3KZT555UGL6GPFDDCCBP-CZNWQDQQC76FC5MI\") #Connect to the Anvil server with unique ID"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment (dev)\" as SERVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTKwgpHGD733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108bf5ac-d1c7-46d6-b7c9-fa828207239e"
      },
      "source": [
        "!unzip BDA_Endsem_Anvil_Files.zip #Unzips all the files required"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  BDA_Endsem_Anvil_Files.zip\n",
            "replace vec/metadata/part-00000? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: vec/metadata/part-00000  \n",
            "replace vec/metadata/_SUCCESS? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: vec/metadata/_SUCCESS   \n",
            "replace stop_words/metadata/part-00000? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: stop_words/metadata/part-00000  \n",
            "replace stop_words/metadata/_SUCCESS? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: stop_words/metadata/_SUCCESS  \n",
            "replace svm_model/data/part-00000-1dba9347-3883-4895-8117-a515e67d221c-c000.snappy.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: svm_model/data/part-00000-1dba9347-3883-4895-8117-a515e67d221c-c000.snappy.parquet  \n",
            "replace svm_model/data/_SUCCESS? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: svm_model/data/_SUCCESS  \n",
            "replace svm_model/metadata/part-00000? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: svm_model/metadata/part-00000  \n",
            "replace svm_model/metadata/_SUCCESS? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: svm_model/metadata/_SUCCESS  \n",
            "replace tokenizer/metadata/part-00000? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: tokenizer/metadata/part-00000  \n",
            "replace tokenizer/metadata/_SUCCESS? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: tokenizer/metadata/_SUCCESS  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh5_fwPmAZr4"
      },
      "source": [
        "#Load the pre-saved SVM Models and all the vectorizers\n",
        "loaded_tok=RegexTokenizer.load(\"tokenizer\")\n",
        "loaded_stop=StopWordsRemover.load(\"stop_words\")\n",
        "loaded_vec=HashingTF.load(\"vec\")\n",
        "loaded_model=SVMModel.load(sc,\"svm_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EZ0iRPdsYzr"
      },
      "source": [
        "## **Main Functions for Computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOHdXeReJEFi"
      },
      "source": [
        "#Funtion to convert a Sparse and Dense vector to MLLIB format\n",
        "def as_mllib(v):\n",
        "    if isinstance(v, ml_linalg.SparseVector):\n",
        "        return MLLibVectors.sparse(v.size, v.indices, v.values)\n",
        "    elif isinstance(v, ml_linalg.DenseVector):\n",
        "        return MLLibVectors.dense(v.toArray())\n",
        "    else:\n",
        "        raise TypeError(\"Unsupported type: {0}\".format(type(v)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udKb-53vwo3m"
      },
      "source": [
        "### **Instructions for running the GUI**\n",
        "\n",
        "[Anvil GUI](https://CZNWQDQQC76FC5MI.anvil.app/CTX52FSLFD4YJVPTIRVSXLSV)\n",
        "\n",
        "\n",
        "> This is the link that connects you to the Anvil Web.\n",
        "**Run the next cell first and then enter your reviews**\n",
        "\n",
        "\n",
        "\n",
        "**Example Positive Review** -> My, that cup helped me so much. I made steaming hot coffee one day and clumsy me dropped the cup,but it was so strong that it didn't break at all.\n",
        "\n",
        "**Example Negative Review** -> My experience with this watch was abysmal. The day after I bought it, it stopped working and it took me INR 1000 to fix. It worked exactly for one more week and stopped again. Don't buy this and save your money\n",
        "\n",
        "Manually stop running the next cell after usage\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XPLMol8AZpi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c6fc0a35-1125-4ffc-bba5-27c2814c7b51"
      },
      "source": [
        "@anvil.server.callable #To call the Anvil Server\n",
        "\n",
        "#Function that classifies a review\n",
        "def classify(document):\n",
        "  doc_list=[document]\n",
        "  df=spark.createDataFrame(doc_list,StringType())\n",
        "  label = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "  #Tokenizer\n",
        "  loaded_tok.setInputCol(\"value\")\n",
        "  loaded_tok.setOutputCol(\"Words\")\n",
        "  X1=loaded_tok.transform(df)\n",
        "  \n",
        "  #Remove Stop Words\n",
        "  loaded_stop.setInputCol(\"Words\")\n",
        "  loaded_stop.setOutputCol(\"Important_words\")\n",
        "  X2=loaded_stop.transform(X1)\n",
        "  \n",
        "  #Hashing TF\n",
        "  loaded_vec.setInputCol(\"Important_words\")\n",
        "  loaded_vec.setOutputCol(\"Features\")\n",
        "  X = loaded_vec.transform(X2)\n",
        "  r = X.rdd.map(lambda d:as_mllib(d['Features']))\n",
        "\n",
        "  #Predict the label of the review\n",
        "  y = loaded_model.predict(r)\n",
        "  y =  y.collect()[0]\n",
        "  return label[y]\n",
        "\n",
        "anvil.server.wait_forever() #Server waits until manual termination"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0fbfb854abcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Server waits until manual termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sanLRZBwrEuU"
      },
      "source": [
        "## **Thank You!**"
      ]
    }
  ]
}